var __extends = (this && this.__extends) || (function () {
    var extendStatics = function (d, b) {
        extendStatics = Object.setPrototypeOf ||
            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||
            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };
        return extendStatics(d, b);
    };
    return function (d, b) {
        if (typeof b !== "function" && b !== null)
            throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
        extendStatics(d, b);
        function __() { this.constructor = d; }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    };
})();
var __assign = (this && this.__assign) || function () {
    __assign = Object.assign || function(t) {
        for (var s, i = 1, n = arguments.length; i < n; i++) {
            s = arguments[i];
            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))
                t[p] = s[p];
        }
        return t;
    };
    return __assign.apply(this, arguments);
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __generator = (this && this.__generator) || function (thisArg, body) {
    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;
    return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
    function verb(n) { return function (v) { return step([n, v]); }; }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while (g && (g = 0, op[0] && (_ = 0)), _) try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [op[0] & 2, t.value];
            switch (op[0]) {
                case 0: case 1: t = op; break;
                case 4: _.label++; return { value: op[1], done: false };
                case 5: _.label++; y = op[1]; op = [0]; continue;
                case 7: op = _.ops.pop(); _.trys.pop(); continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                    if (t[2]) _.ops.pop();
                    _.trys.pop(); continue;
            }
            op = body.call(thisArg, _);
        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
    }
};
var __rest = (this && this.__rest) || function (s, e) {
    var t = {};
    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)
        t[p] = s[p];
    if (s != null && typeof Object.getOwnPropertySymbols === "function")
        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {
            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))
                t[p[i]] = s[p[i]];
        }
    return t;
};
var __asyncValues = (this && this.__asyncValues) || function (o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i);
    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }
    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }
};
var __read = (this && this.__read) || function (o, n) {
    var m = typeof Symbol === "function" && o[Symbol.iterator];
    if (!m) return o;
    var i = m.call(o), r, ar = [], e;
    try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);
    }
    catch (error) { e = { error: error }; }
    finally {
        try {
            if (r && !r.done && (m = i["return"])) m.call(i);
        }
        finally { if (e) throw e.error; }
    }
    return ar;
};
var __values = (this && this.__values) || function(o) {
    var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
    if (m) return m.call(o);
    if (o && typeof o.length === "number") return {
        next: function () {
            if (o && i >= o.length) o = void 0;
            return { value: o && o[i++], done: !o };
        }
    };
    throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
};
import { InstrumentationBase, InstrumentationNodeModuleDefinition, safeExecuteInTheMiddle, } from "@opentelemetry/instrumentation";
import { diag, context, trace, SpanKind, SpanStatusCode, } from "@opentelemetry/api";
import { VERSION } from "./version";
import { SemanticConventions, OpenInferenceSpanKind, MimeType, } from "@arizeai/openinference-semantic-conventions";
import { assertUnreachable, isString } from "./typeUtils";
import { isTracingSuppressed } from "@opentelemetry/core";
var MODULE_NAME = "openai";
/**
 * Flag to check if the openai module has been patched
 * Note: This is a fallback in case the module is made immutable (e.x. Deno, webpack, etc.)
 */
var _isOpenInferencePatched = false;
/**
 * function to check if instrumentation is enabled / disabled
 */
export function isPatched() {
    return _isOpenInferencePatched;
}
/**
 * Resolves the execution context for the current span
 * If tracing is suppressed, the span is dropped and the current context is returned
 * @param span
 */
function getExecContext(span) {
    var activeContext = context.active();
    var suppressTracing = isTracingSuppressed(activeContext);
    var execContext = suppressTracing
        ? trace.setSpan(context.active(), span)
        : activeContext;
    // Drop the span from the context
    if (suppressTracing) {
        trace.deleteSpan(activeContext);
    }
    return execContext;
}
var OpenAIInstrumentation = /** @class */ (function (_super) {
    __extends(OpenAIInstrumentation, _super);
    function OpenAIInstrumentation(config) {
        return _super.call(this, "@arizeai/openinference-instrumentation-openai", VERSION, Object.assign({}, config)) || this;
    }
    OpenAIInstrumentation.prototype.init = function () {
        var module = new InstrumentationNodeModuleDefinition("openai", ["^4.0.0"], this.patch.bind(this), this.unpatch.bind(this));
        return module;
    };
    /**
     * Manually instruments the OpenAI module. This is needed when the module is not loaded via require (commonjs)
     * @param {openai} module
     */
    OpenAIInstrumentation.prototype.manuallyInstrument = function (module) {
        diag.debug("Manually instrumenting ".concat(MODULE_NAME));
        this.patch(module);
    };
    /**
     * Patches the OpenAI module
     */
    OpenAIInstrumentation.prototype.patch = function (module, moduleVersion) {
        diag.debug("Applying patch for ".concat(MODULE_NAME, "@").concat(moduleVersion));
        if ((module === null || module === void 0 ? void 0 : module.openInferencePatched) || _isOpenInferencePatched) {
            return module;
        }
        // eslint-disable-next-line @typescript-eslint/no-this-alias
        var instrumentation = this;
        // Patch create chat completions
        this._wrap(module.OpenAI.Chat.Completions.prototype, "create", 
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        function (original) {
            return function patchedCreate() {
                var _a;
                var _this = this;
                var args = [];
                for (var _i = 0; _i < arguments.length; _i++) {
                    args[_i] = arguments[_i];
                }
                var body = args[0];
                var _messages = body.messages, invocationParameters = __rest(body, ["messages"]);
                var span = instrumentation.tracer.startSpan("OpenAI Chat Completions", {
                    kind: SpanKind.INTERNAL,
                    attributes: __assign((_a = {}, _a[SemanticConventions.OPENINFERENCE_SPAN_KIND] = OpenInferenceSpanKind.LLM, _a[SemanticConventions.LLM_MODEL_NAME] = body.model, _a[SemanticConventions.INPUT_VALUE] = JSON.stringify(body), _a[SemanticConventions.INPUT_MIME_TYPE] = MimeType.JSON, _a[SemanticConventions.LLM_INVOCATION_PARAMETERS] = JSON.stringify(invocationParameters), _a), getLLMInputMessagesAttributes(body)),
                });
                var execContext = getExecContext(span);
                var execPromise = safeExecuteInTheMiddle(function () {
                    return context.with(execContext, function () {
                        return original.apply(_this, args);
                    });
                }, function (error) {
                    // Push the error to the span
                    if (error) {
                        span.recordException(error);
                        span.setStatus({
                            code: SpanStatusCode.ERROR,
                            message: error.message,
                        });
                        span.end();
                    }
                });
                var wrappedPromise = execPromise.then(function (result) {
                    var _a;
                    if (isChatCompletionResponse(result)) {
                        // Record the results
                        span.setAttributes(__assign(__assign((_a = {}, _a[SemanticConventions.OUTPUT_VALUE] = JSON.stringify(result), _a[SemanticConventions.OUTPUT_MIME_TYPE] = MimeType.JSON, _a[SemanticConventions.LLM_MODEL_NAME] = result.model, _a), getChatCompletionLLMOutputMessagesAttributes(result)), getUsageAttributes(result)));
                        span.setStatus({ code: SpanStatusCode.OK });
                        span.end();
                    }
                    else {
                        // This is a streaming response
                        // handle the chunks and add them to the span
                        // First split the stream via tee
                        var _b = __read(result.tee(), 2), leftStream = _b[0], rightStream = _b[1];
                        consumeChatCompletionStreamChunks(rightStream, span);
                        result = leftStream;
                    }
                    return result;
                });
                return context.bind(execContext, wrappedPromise);
            };
        });
        this._wrap(module.OpenAI.Completions.prototype, "create", 
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        function (original) {
            return function patchedCreate() {
                var _a;
                var _this = this;
                var args = [];
                for (var _i = 0; _i < arguments.length; _i++) {
                    args[_i] = arguments[_i];
                }
                var body = args[0];
                var _prompt = body.prompt, invocationParameters = __rest(body, ["prompt"]);
                var span = instrumentation.tracer.startSpan("OpenAI Completions", {
                    kind: SpanKind.INTERNAL,
                    attributes: __assign((_a = {}, _a[SemanticConventions.OPENINFERENCE_SPAN_KIND] = OpenInferenceSpanKind.LLM, _a[SemanticConventions.LLM_MODEL_NAME] = body.model, _a[SemanticConventions.LLM_INVOCATION_PARAMETERS] = JSON.stringify(invocationParameters), _a), getCompletionInputValueAndMimeType(body)),
                });
                var execContext = getExecContext(span);
                var execPromise = safeExecuteInTheMiddle(function () {
                    return context.with(execContext, function () {
                        return original.apply(_this, args);
                    });
                }, function (error) {
                    // Push the error to the span
                    if (error) {
                        span.recordException(error);
                        span.setStatus({
                            code: SpanStatusCode.ERROR,
                            message: error.message,
                        });
                        span.end();
                    }
                });
                var wrappedPromise = execPromise.then(function (result) {
                    var _a;
                    if (isCompletionResponse(result)) {
                        // Record the results
                        span.setAttributes(__assign(__assign((_a = {}, _a[SemanticConventions.OUTPUT_VALUE] = JSON.stringify(result), _a[SemanticConventions.OUTPUT_MIME_TYPE] = MimeType.JSON, _a[SemanticConventions.LLM_MODEL_NAME] = result.model, _a), getCompletionOutputValueAndMimeType(result)), getUsageAttributes(result)));
                        span.setStatus({ code: SpanStatusCode.OK });
                        span.end();
                    }
                    return result;
                });
                return context.bind(execContext, wrappedPromise);
            };
        });
        this._wrap(module.OpenAI.Embeddings.prototype, "create", 
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        function (original) {
            return function patchedEmbeddingCreate() {
                var _a;
                var _this = this;
                var args = [];
                for (var _i = 0; _i < arguments.length; _i++) {
                    args[_i] = arguments[_i];
                }
                var body = args[0];
                var input = body.input;
                var isStringInput = typeof input === "string";
                var span = instrumentation.tracer.startSpan("OpenAI Embeddings", {
                    kind: SpanKind.INTERNAL,
                    attributes: __assign((_a = {}, _a[SemanticConventions.OPENINFERENCE_SPAN_KIND] = OpenInferenceSpanKind.EMBEDDING, _a[SemanticConventions.EMBEDDING_MODEL_NAME] = body.model, _a[SemanticConventions.INPUT_VALUE] = isStringInput
                        ? input
                        : JSON.stringify(input), _a[SemanticConventions.INPUT_MIME_TYPE] = isStringInput
                        ? MimeType.TEXT
                        : MimeType.JSON, _a), getEmbeddingTextAttributes(body)),
                });
                var execContext = getExecContext(span);
                var execPromise = safeExecuteInTheMiddle(function () {
                    return context.with(execContext, function () {
                        return original.apply(_this, args);
                    });
                }, function (error) {
                    // Push the error to the span
                    if (error) {
                        span.recordException(error);
                        span.setStatus({
                            code: SpanStatusCode.ERROR,
                            message: error.message,
                        });
                        span.end();
                    }
                });
                var wrappedPromise = execPromise.then(function (result) {
                    if (result) {
                        // Record the results
                        span.setAttributes(__assign({}, getEmbeddingEmbeddingsAttributes(result)));
                    }
                    span.setStatus({ code: SpanStatusCode.OK });
                    span.end();
                    return result;
                });
                return context.bind(execContext, wrappedPromise);
            };
        });
        _isOpenInferencePatched = true;
        try {
            // This can fail if the module is made immutable via the runtime or bundler
            module.openInferencePatched = true;
        }
        catch (e) {
            diag.warn("Failed to set ".concat(MODULE_NAME, " patched flag on the module"), e);
        }
        return module;
    };
    /**
     * Un-patches the OpenAI module's chat completions API
     */
    OpenAIInstrumentation.prototype.unpatch = function (moduleExports, moduleVersion) {
        diag.debug("Removing patch for ".concat(MODULE_NAME, "@").concat(moduleVersion));
        this._unwrap(moduleExports.OpenAI.Chat.Completions.prototype, "create");
        this._unwrap(moduleExports.OpenAI.Completions.prototype, "create");
        this._unwrap(moduleExports.OpenAI.Embeddings.prototype, "create");
        _isOpenInferencePatched = false;
        try {
            // This can fail if the module is made immutable via the runtime or bundler
            moduleExports.openInferencePatched = false;
        }
        catch (e) {
            diag.warn("Failed to unset ".concat(MODULE_NAME, " patched flag on the module"), e);
        }
    };
    return OpenAIInstrumentation;
}(InstrumentationBase));
export { OpenAIInstrumentation };
/**
 * type-guard that checks if the response is a chat completion response
 */
function isChatCompletionResponse(response) {
    return "choices" in response;
}
/**
 * type-guard that checks if the response is a completion response
 */
function isCompletionResponse(response) {
    return "choices" in response;
}
/**
 * type-guard that checks if completion prompt attribute is an array of strings
 */
function isPromptStringArray(prompt) {
    return (Array.isArray(prompt) && prompt.every(function (item) { return typeof item === "string"; }));
}
/**
 * Converts the body of a chat completions request to LLM input messages
 */
function getLLMInputMessagesAttributes(body) {
    return body.messages.reduce(function (acc, message, index) {
        var e_1, _a;
        var messageAttributes = getChatCompletionInputMessageAttributes(message);
        var indexPrefix = "".concat(SemanticConventions.LLM_INPUT_MESSAGES, ".").concat(index, ".");
        try {
            // Flatten the attributes on the index prefix
            for (var _b = __values(Object.entries(messageAttributes)), _c = _b.next(); !_c.done; _c = _b.next()) {
                var _d = __read(_c.value, 2), key = _d[0], value = _d[1];
                acc["".concat(indexPrefix).concat(key)] = value;
            }
        }
        catch (e_1_1) { e_1 = { error: e_1_1 }; }
        finally {
            try {
                if (_c && !_c.done && (_a = _b.return)) _a.call(_b);
            }
            finally { if (e_1) throw e_1.error; }
        }
        return acc;
    }, {});
}
function getChatCompletionInputMessageAttributes(message) {
    var _a;
    var role = message.role;
    var attributes = (_a = {},
        _a[SemanticConventions.MESSAGE_ROLE] = role,
        _a);
    // Add the content only if it is a string
    if (typeof message.content === "string")
        attributes[SemanticConventions.MESSAGE_CONTENT] = message.content;
    switch (role) {
        case "user":
            // There's nothing to add for the user
            break;
        case "assistant":
            if (message.tool_calls) {
                message.tool_calls.forEach(function (toolCall, index) {
                    // Make sure the tool call has a function
                    if (toolCall.function) {
                        var toolCallIndexPrefix = "".concat(SemanticConventions.MESSAGE_TOOL_CALLS, ".").concat(index, ".");
                        attributes[toolCallIndexPrefix + SemanticConventions.TOOL_CALL_FUNCTION_NAME] = toolCall.function.name;
                        attributes[toolCallIndexPrefix +
                            SemanticConventions.TOOL_CALL_FUNCTION_ARGUMENTS_JSON] = toolCall.function.arguments;
                    }
                });
            }
            break;
        case "function":
            attributes[SemanticConventions.MESSAGE_FUNCTION_CALL_NAME] = message.name;
            break;
        case "tool":
            // There's nothing to add for the tool. There is a tool_id, but there are no
            // semantic conventions for it
            break;
        case "system":
            // There's nothing to add for the system. Content is captured above
            break;
        default:
            assertUnreachable(role);
            break;
    }
    return attributes;
}
/**
 * Converts the body of a completions request to input attributes
 */
function getCompletionInputValueAndMimeType(body) {
    var _a, _b;
    if (typeof body.prompt === "string") {
        return _a = {},
            _a[SemanticConventions.INPUT_VALUE] = body.prompt,
            _a[SemanticConventions.INPUT_MIME_TYPE] = MimeType.TEXT,
            _a;
    }
    else if (isPromptStringArray(body.prompt)) {
        var prompt = body.prompt[0]; // Only single prompts are currently supported
        if (prompt === undefined) {
            return {};
        }
        return _b = {},
            _b[SemanticConventions.INPUT_VALUE] = prompt,
            _b[SemanticConventions.INPUT_MIME_TYPE] = MimeType.TEXT,
            _b;
    }
    // Other cases in which the prompt is a token or array of tokens are currently unsupported
    return {};
}
/**
 * Get usage attributes
 */
function getUsageAttributes(completion) {
    var _a;
    if (completion.usage) {
        return _a = {},
            _a[SemanticConventions.LLM_TOKEN_COUNT_COMPLETION] = completion.usage.completion_tokens,
            _a[SemanticConventions.LLM_TOKEN_COUNT_PROMPT] = completion.usage.prompt_tokens,
            _a[SemanticConventions.LLM_TOKEN_COUNT_TOTAL] = completion.usage.total_tokens,
            _a;
    }
    return {};
}
/**
 * Converts the chat completion result to LLM output attributes
 */
function getChatCompletionLLMOutputMessagesAttributes(chatCompletion) {
    // Right now support just the first choice
    var choice = chatCompletion.choices[0];
    if (!choice) {
        return {};
    }
    return [choice.message].reduce(function (acc, message, index) {
        var e_2, _a;
        var indexPrefix = "".concat(SemanticConventions.LLM_OUTPUT_MESSAGES, ".").concat(index, ".");
        var messageAttributes = getChatCompletionOutputMessageAttributes(message);
        try {
            // Flatten the attributes on the index prefix
            for (var _b = __values(Object.entries(messageAttributes)), _c = _b.next(); !_c.done; _c = _b.next()) {
                var _d = __read(_c.value, 2), key = _d[0], value = _d[1];
                acc["".concat(indexPrefix).concat(key)] = value;
            }
        }
        catch (e_2_1) { e_2 = { error: e_2_1 }; }
        finally {
            try {
                if (_c && !_c.done && (_a = _b.return)) _a.call(_b);
            }
            finally { if (e_2) throw e_2.error; }
        }
        return acc;
    }, {});
}
function getChatCompletionOutputMessageAttributes(message) {
    var _a;
    var role = message.role;
    var attributes = (_a = {},
        _a[SemanticConventions.MESSAGE_ROLE] = role,
        _a);
    if (message.content) {
        attributes[SemanticConventions.MESSAGE_CONTENT] = message.content;
    }
    if (message.tool_calls) {
        message.tool_calls.forEach(function (toolCall, index) {
            var toolCallIndexPrefix = "".concat(SemanticConventions.MESSAGE_TOOL_CALLS, ".").concat(index, ".");
            // Double check that the tool call has a function
            // NB: OpenAI only supports tool calls with functions right now but this may change
            if (toolCall.function) {
                attributes[toolCallIndexPrefix + SemanticConventions.TOOL_CALL_FUNCTION_NAME] = toolCall.function.name;
                attributes[toolCallIndexPrefix +
                    SemanticConventions.TOOL_CALL_FUNCTION_ARGUMENTS_JSON] = toolCall.function.arguments;
            }
        });
    }
    if (message.function_call) {
        attributes[SemanticConventions.MESSAGE_FUNCTION_CALL_NAME] =
            message.function_call.name;
        attributes[SemanticConventions.MESSAGE_FUNCTION_CALL_ARGUMENTS_JSON] =
            message.function_call.arguments;
    }
    return attributes;
}
/**
 * Converts the completion result to output attributes
 */
function getCompletionOutputValueAndMimeType(completion) {
    var _a;
    // Right now support just the first choice
    var choice = completion.choices[0];
    if (!choice) {
        return {};
    }
    return _a = {},
        _a[SemanticConventions.OUTPUT_VALUE] = String(choice.text),
        _a[SemanticConventions.OUTPUT_MIME_TYPE] = MimeType.TEXT,
        _a;
}
/**
 * Converts the embedding result payload to embedding attributes
 */
function getEmbeddingTextAttributes(request) {
    var _a;
    if (typeof request.input === "string") {
        return _a = {},
            _a["".concat(SemanticConventions.EMBEDDING_EMBEDDINGS, ".0.").concat(SemanticConventions.EMBEDDING_TEXT)] = request.input,
            _a;
    }
    else if (Array.isArray(request.input) &&
        request.input.length > 0 &&
        typeof request.input[0] === "string") {
        return request.input.reduce(function (acc, input, index) {
            var indexPrefix = "".concat(SemanticConventions.EMBEDDING_EMBEDDINGS, ".").concat(index, ".");
            acc["".concat(indexPrefix).concat(SemanticConventions.EMBEDDING_TEXT)] = input;
            return acc;
        }, {});
    }
    // Ignore other cases where input is a number or an array of numbers
    return {};
}
/**
 * Converts the embedding result payload to embedding attributes
 */
function getEmbeddingEmbeddingsAttributes(response) {
    return response.data.reduce(function (acc, embedding, index) {
        var indexPrefix = "".concat(SemanticConventions.EMBEDDING_EMBEDDINGS, ".").concat(index, ".");
        acc["".concat(indexPrefix).concat(SemanticConventions.EMBEDDING_VECTOR)] =
            embedding.embedding;
        return acc;
    }, {});
}
/**
 * Consumes the stream chunks and adds them to the span
 */
function consumeChatCompletionStreamChunks(stream, span) {
    var _a, stream_1, stream_1_1;
    var _b, e_3, _c, _d;
    return __awaiter(this, void 0, void 0, function () {
        var streamResponse, toolAndFunctionCallAttributes, chunk, choice, toolAndFunctionCallAttributesDiff, _e, _f, _g, key, value, e_3_1, messageIndexPrefix, attributes, _h, _j, _k, key, value;
        var e_4, _l, _m, e_5, _o;
        return __generator(this, function (_p) {
            switch (_p.label) {
                case 0:
                    streamResponse = "";
                    toolAndFunctionCallAttributes = {};
                    _p.label = 1;
                case 1:
                    _p.trys.push([1, 6, 7, 12]);
                    _a = true, stream_1 = __asyncValues(stream);
                    _p.label = 2;
                case 2: return [4 /*yield*/, stream_1.next()];
                case 3:
                    if (!(stream_1_1 = _p.sent(), _b = stream_1_1.done, !_b)) return [3 /*break*/, 5];
                    _d = stream_1_1.value;
                    _a = false;
                    chunk = _d;
                    if (chunk.choices.length <= 0) {
                        return [3 /*break*/, 4];
                    }
                    choice = chunk.choices[0];
                    if (choice.delta.content) {
                        streamResponse += choice.delta.content;
                    }
                    toolAndFunctionCallAttributesDiff = getToolAndFunctionCallAttributesFromStreamChunk(chunk);
                    try {
                        for (_e = (e_4 = void 0, __values(Object.entries(toolAndFunctionCallAttributesDiff))), _f = _e.next(); !_f.done; _f = _e.next()) {
                            _g = __read(_f.value, 2), key = _g[0], value = _g[1];
                            if (isString(toolAndFunctionCallAttributes[key]) && isString(value)) {
                                toolAndFunctionCallAttributes[key] += value;
                            }
                            else if (isString(value)) {
                                toolAndFunctionCallAttributes[key] = value;
                            }
                        }
                    }
                    catch (e_4_1) { e_4 = { error: e_4_1 }; }
                    finally {
                        try {
                            if (_f && !_f.done && (_l = _e.return)) _l.call(_e);
                        }
                        finally { if (e_4) throw e_4.error; }
                    }
                    _p.label = 4;
                case 4:
                    _a = true;
                    return [3 /*break*/, 2];
                case 5: return [3 /*break*/, 12];
                case 6:
                    e_3_1 = _p.sent();
                    e_3 = { error: e_3_1 };
                    return [3 /*break*/, 12];
                case 7:
                    _p.trys.push([7, , 10, 11]);
                    if (!(!_a && !_b && (_c = stream_1.return))) return [3 /*break*/, 9];
                    return [4 /*yield*/, _c.call(stream_1)];
                case 8:
                    _p.sent();
                    _p.label = 9;
                case 9: return [3 /*break*/, 11];
                case 10:
                    if (e_3) throw e_3.error;
                    return [7 /*endfinally*/];
                case 11: return [7 /*endfinally*/];
                case 12:
                    messageIndexPrefix = "".concat(SemanticConventions.LLM_OUTPUT_MESSAGES, ".0.");
                    attributes = (_m = {},
                        _m[SemanticConventions.OUTPUT_VALUE] = streamResponse,
                        _m[SemanticConventions.OUTPUT_MIME_TYPE] = MimeType.TEXT,
                        _m["".concat(messageIndexPrefix).concat(SemanticConventions.MESSAGE_CONTENT)] = streamResponse,
                        _m["".concat(messageIndexPrefix).concat(SemanticConventions.MESSAGE_ROLE)] = "assistant",
                        _m);
                    try {
                        // Add the tool and function call attributes
                        for (_h = __values(Object.entries(toolAndFunctionCallAttributes)), _j = _h.next(); !_j.done; _j = _h.next()) {
                            _k = __read(_j.value, 2), key = _k[0], value = _k[1];
                            attributes["".concat(messageIndexPrefix).concat(key)] = value;
                        }
                    }
                    catch (e_5_1) { e_5 = { error: e_5_1 }; }
                    finally {
                        try {
                            if (_j && !_j.done && (_o = _h.return)) _o.call(_h);
                        }
                        finally { if (e_5) throw e_5.error; }
                    }
                    span.setAttributes(attributes);
                    span.end();
                    return [2 /*return*/];
            }
        });
    });
}
/**
 * Extracts the semantic attributes from the stream chunk for tool_calls and function_calls
 */
function getToolAndFunctionCallAttributesFromStreamChunk(chunk) {
    if (chunk.choices.length <= 0) {
        return {};
    }
    var choice = chunk.choices[0];
    var attributes = {};
    if (choice.delta.tool_calls) {
        choice.delta.tool_calls.forEach(function (toolCall, index) {
            var toolCallIndexPrefix = "".concat(SemanticConventions.MESSAGE_TOOL_CALLS, ".").concat(index, ".");
            // Double check that the tool call has a function
            // NB: OpenAI only supports tool calls with functions right now but this may change
            if (toolCall.function) {
                attributes[toolCallIndexPrefix + SemanticConventions.TOOL_CALL_FUNCTION_NAME] = toolCall.function.name;
                attributes[toolCallIndexPrefix +
                    SemanticConventions.TOOL_CALL_FUNCTION_ARGUMENTS_JSON] = toolCall.function.arguments;
            }
        });
    }
    if (choice.delta.function_call) {
        attributes[SemanticConventions.MESSAGE_FUNCTION_CALL_NAME] =
            choice.delta.function_call.name;
        attributes[SemanticConventions.MESSAGE_FUNCTION_CALL_ARGUMENTS_JSON] =
            choice.delta.function_call.arguments;
    }
    return attributes;
}
//# sourceMappingURL=instrumentation.js.map